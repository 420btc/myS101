"use client";

import { useEffect, useRef, useState } from "react";
import * as faceapi from 'face-api.js';
import { Button } from "@/components/ui/button";
import { Camera, CameraOff, X, Eye, EyeOff } from "lucide-react";

interface WebcamViewProps {
  show: boolean;
  onHide: () => void;
  className?: string;
  onRobotControl?: (direction: 'left' | 'right' | 'center') => void;
}

export default function WebcamView({ show, onHide, className = "", onRobotControl }: WebcamViewProps) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [isActive, setIsActive] = useState(false);
  const [stream, setStream] = useState<MediaStream | null>(null);
  const [error, setError] = useState<string>("");
  const [isMinimized, setIsMinimized] = useState(false);
  const [modelsLoaded, setModelsLoaded] = useState(false);
  const [faceTrackingEnabled, setFaceTrackingEnabled] = useState(false);
  const intervalRef = useRef<NodeJS.Timeout | null>(null);
  const lastFacePositionRef = useRef<'left' | 'right' | 'center'>('center');

  useEffect(() => {
    const loadModels = async () => {
      try {
        // Intentar m√∫ltiples rutas para compatibilidad con producci√≥n
        const modelPaths = [
          '/models',           // Ruta local de desarrollo
          './models',          // Ruta relativa
          '/public/models',    // Ruta alternativa
          'https://cdn.jsdelivr.net/npm/@vladmandic/face-api@latest/model' // CDN de respaldo
        ];
        
        let modelsLoadedSuccessfully = false;
        let lastError = null;
        
        for (const modelPath of modelPaths) {
          try {
            // Solo cargar el modelo TinyFaceDetector para detecci√≥n b√°sica de rostros
            await faceapi.nets.tinyFaceDetector.loadFromUri(modelPath);
            
            modelsLoadedSuccessfully = true;
            break;
          } catch (pathError) {
            lastError = pathError;
            continue;
          }
        }
        
        if (modelsLoadedSuccessfully) {
          setModelsLoaded(true);
        } else {
          throw lastError || new Error('No se pudieron cargar los modelos desde ninguna ruta');
        }
        
      } catch (error) {
        setModelsLoaded(false);
        setError('Error cargando modelos de detecci√≥n facial. Revisa la consola para m√°s detalles.');
      }
    };
    
    // Agregar un peque√±o delay para asegurar que el DOM est√© listo
    setTimeout(loadModels, 1000);

    return () => {
      if (intervalRef.current) {
        clearInterval(intervalRef.current);
      }
    };
  }, []);

  const startWebcam = async () => {
    console.log('üìπ Intentando iniciar webcam...');
    
    // Verificar si estamos en HTTPS (requerido para c√°mara en producci√≥n)
    if (typeof window !== 'undefined') {
      const isHTTPS = window.location.protocol === 'https:';
      const isLocalhost = window.location.hostname === 'localhost' || window.location.hostname === '127.0.0.1';
      
      console.log('üîí Protocolo:', window.location.protocol);
      console.log('üè† Hostname:', window.location.hostname);
      
      if (!isHTTPS && !isLocalhost) {
        console.error('‚ùå HTTPS requerido para acceso a c√°mara en producci√≥n');
        setError('HTTPS es requerido para acceder a la c√°mara en producci√≥n. Aseg√∫rate de que tu sitio use HTTPS.');
        return;
      }
    }
    
    try {
      // Verificar disponibilidad de getUserMedia
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('getUserMedia no est√° disponible en este navegador');
      }
      
      console.log('üé• Solicitando permisos de c√°mara...');
      
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          width: { ideal: 640 },
          height: { ideal: 480 },
          facingMode: 'user'
        }
      });
      
      console.log('‚úÖ Webcam activada correctamente');
      console.log('üìä Stream info:', {
        active: stream.active,
        tracks: stream.getVideoTracks().length,
        settings: stream.getVideoTracks()[0]?.getSettings()
      });
      
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        console.log('üîó Stream asignado al elemento video');
      }
      
      setStream(stream);
      setIsActive(true);
      setError("");
      
    } catch (error: any) {
      console.error('‚ùå Error iniciando webcam:', error);
      
      // Mensajes de error espec√≠ficos para producci√≥n
      let errorMessage = 'Error desconocido al acceder a la c√°mara';
      
      if (error.name === 'NotAllowedError') {
        errorMessage = 'Permisos de c√°mara denegados. Por favor, permite el acceso a la c√°mara y recarga la p√°gina.';
      } else if (error.name === 'NotFoundError') {
        errorMessage = 'No se encontr√≥ ninguna c√°mara. Verifica que tu dispositivo tenga una c√°mara conectada.';
      } else if (error.name === 'NotSupportedError') {
        errorMessage = 'Acceso a c√°mara no soportado. Aseg√∫rate de usar HTTPS en producci√≥n.';
      } else if (error.name === 'NotReadableError') {
        errorMessage = 'C√°mara en uso por otra aplicaci√≥n. Cierra otras aplicaciones que puedan estar usando la c√°mara.';
      } else if (error.message.includes('getUserMedia')) {
        errorMessage = 'Tu navegador no soporta acceso a c√°mara o necesitas HTTPS para producci√≥n.';
      }
      
      console.error('üí° Sugerencias para resolver el error:');
      console.error('   1. Verificar que el sitio use HTTPS en producci√≥n');
      console.error('   2. Verificar permisos de c√°mara en el navegador');
      console.error('   3. Verificar que no haya otras aplicaciones usando la c√°mara');
      console.error('   4. Probar en un navegador diferente');
      
      setError(errorMessage);
      setIsActive(false);
    }
  };

  const stopWebcam = () => {
    if (intervalRef.current) {
      clearInterval(intervalRef.current);
    }
    if (stream) {
      stream.getTracks().forEach(track => track.stop());
      setStream(null);
    }
    if (videoRef.current) {
      videoRef.current.srcObject = null;
    }
    setIsActive(false);
  };

  const detectFaces = async () => {
    if (!videoRef.current || !canvasRef.current || !modelsLoaded) {
      return;
    }

    const video = videoRef.current;
    const canvas = canvasRef.current;
    
    if (video.paused || video.ended) {
      return;
    }

    try {
      const currentTime = Date.now();
      
      // Log para verificar que la funci√≥n se ejecuta
      console.log('üîç detectFaces ejecut√°ndose - Seguimiento habilitado:', faceTrackingEnabled);
      
      // Solo detectar rostros si el seguimiento facial est√° habilitado
      if (faceTrackingEnabled) {
        console.log('üëÅÔ∏è Iniciando detecci√≥n de rostros...');
        
        // Detectar rostros con m√°xima precisi√≥n para movimientos milim√©tricos
        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions({
          inputSize: 512,
          scoreThreshold: 0.2
        }));
        
        console.log('üìä Rostros detectados:', detections.length);
        
        const displaySize = { width: video.videoWidth, height: video.videoHeight };
        faceapi.matchDimensions(canvas, displaySize);
        const resizedDetections = faceapi.resizeResults(detections, displaySize);
        
        const ctx = canvas.getContext('2d');
        if (ctx) {
          ctx.clearRect(0, 0, canvas.width, canvas.height);
          
          // Dibujar l√≠neas de referencia para las zonas de control
          const videoWidth = video.videoWidth;
          const videoHeight = video.videoHeight;
          const leftThreshold = videoWidth * 0.4;
          const rightThreshold = videoWidth * 0.6;
          
          // L√≠neas verticales de zona
          ctx.strokeStyle = 'rgba(255, 255, 0, 0.3)';
          ctx.lineWidth = 1;
          ctx.setLineDash([5, 5]);
          
          // L√≠nea izquierda
          ctx.beginPath();
          ctx.moveTo(leftThreshold, 0);
          ctx.lineTo(leftThreshold, videoHeight);
          ctx.stroke();
          
          // L√≠nea derecha
          ctx.beginPath();
          ctx.moveTo(rightThreshold, 0);
          ctx.lineTo(rightThreshold, videoHeight);
          ctx.stroke();
          
          ctx.setLineDash([]); // Resetear l√≠nea punteada
          
          // Solo dibujar rect√°ngulos de detecci√≥n (sin puntos faciales ni expresiones)
          resizedDetections.forEach((detection, index) => {
            console.log(`üéØ Procesando rostro ${index + 1}:`, detection);
            
            // FaceDetection tiene la propiedad box directamente
            const box = detection.box;
            
            if (box) {
              // Calcular el centro de la detecci√≥n
              const centerX = box.x + box.width / 2;
              const centerY = box.y + box.height / 2;
              
              console.log(`üìç Centro del rostro ${index + 1}: X=${Math.round(centerX)}, Y=${Math.round(centerY)}`);
              
              // Tama√±o fijo del recuadro (80x80 p√≠xeles)
              const fixedSize = 80;
              const halfSize = fixedSize / 2;
              
              // Dibujar recuadro de tama√±o fijo centrado en la detecci√≥n
              ctx.strokeStyle = '#00ff00';
              ctx.lineWidth = 2;
              ctx.strokeRect(
                centerX - halfSize, 
                centerY - halfSize, 
                fixedSize, 
                fixedSize
              );

              // Mostrar coordenadas en tiempo real
              ctx.fillStyle = '#00ff00';
              ctx.font = '14px Arial';
              ctx.fillText(
                `X: ${Math.round(centerX)} Y: ${Math.round(centerY)}`,
                centerX - halfSize,
                centerY - halfSize - 10
              );
              
              // Mostrar zona actual
              let zona = '';
              if (centerX < leftThreshold) {
                zona = 'IZQUIERDA';
                ctx.fillStyle = '#ff6b6b';
              } else if (centerX > rightThreshold) {
                zona = 'DERECHA';
                ctx.fillStyle = '#4ecdc4';
              } else {
                zona = 'CENTRO';
                ctx.fillStyle = '#45b7d1';
              }
              
              ctx.font = '12px Arial';
              ctx.fillText(
                zona,
                centerX - halfSize,
                centerY + halfSize + 20
              );

              // Control del robot basado en posici√≥n del rostro (solo si est√° habilitado)
              if (onRobotControl) {
                let currentPosition: 'left' | 'right' | 'center';
                
                if (centerX < leftThreshold) {
                  currentPosition = 'left';
                } else if (centerX > rightThreshold) {
                  currentPosition = 'right';
                } else {
                  currentPosition = 'center';
                }
                
                // Solo enviar comando si la posici√≥n cambi√≥
                if (currentPosition !== lastFacePositionRef.current) {
                  console.log('üë§ Cambio de posici√≥n facial detectado:', {
                    anterior: lastFacePositionRef.current,
                    nueva: currentPosition,
                    coordenadas: { x: centerX, y: centerY },
                    umbrales: { izquierda: leftThreshold, derecha: rightThreshold }
                  });
                  
                  lastFacePositionRef.current = currentPosition;
                  
                  if (onRobotControl) {
                    console.log('üöÄ Llamando a onRobotControl con:', currentPosition);
                    onRobotControl(currentPosition);
                  } else {
                    console.log('‚ùå onRobotControl no est√° definido');
                  }
                }
              }
            }
          });
        }
      } else {
        // Si el seguimiento facial est√° deshabilitado, limpiar el canvas
        console.log('üëÅÔ∏è‚Äçüó®Ô∏è Seguimiento facial deshabilitado, limpiando canvas');
        const ctx = canvas.getContext('2d');
        if (ctx) {
          ctx.clearRect(0, 0, canvas.width, canvas.height);
        }
      }
    } catch (error) {
      console.error('‚ùå Error en detectFaces:', error);
    }
  };

  const handleVideoPlay = () => {
    console.log('‚ñ∂Ô∏è Video iniciado, configurando detecci√≥n facial...');
    console.log('ü§ñ Modelos cargados:', modelsLoaded);
    console.log('üëÅÔ∏è Seguimiento facial habilitado:', faceTrackingEnabled);
    
    if (!modelsLoaded) {
      console.log('‚ö†Ô∏è Modelos no cargados, no se puede iniciar detecci√≥n');
      return;
    }
    
    // Esperar a que el video tenga dimensiones v√°lidas
    const video = videoRef.current;
    if (video && (video.videoWidth === 0 || video.videoHeight === 0)) {
      console.log('‚è≥ Esperando dimensiones del video...');
      setTimeout(handleVideoPlay, 100);
      return;
    }
    
    console.log('‚úÖ Video listo, iniciando bucle de detecci√≥n');
    
    // Configurar dimensiones del canvas
    const canvas = canvasRef.current;
    if (video && canvas) {
      const displaySize = { width: video.videoWidth, height: video.videoHeight };
      faceapi.matchDimensions(canvas, displaySize);
      console.log('üìê Canvas configurado:', displaySize);
    }
    
    // Iniciar bucle de detecci√≥n continua
    const startDetectionLoop = () => {
      detectFaces();
      if (videoRef.current && !videoRef.current.paused && !videoRef.current.ended) {
        requestAnimationFrame(startDetectionLoop);
      }
    };
    
    startDetectionLoop();
  };

  const toggleWebcam = () => {
    if (isActive) {
      stopWebcam();
    } else {
      startWebcam();
    }
  };

  const closeWebcam = () => {
    stopWebcam();
    onHide();
  };

  useEffect(() => {
    if (show && !isActive) {
      startWebcam();
    } else if (!show && isActive) {
      stopWebcam();
    }
  }, [show]);

  useEffect(() => {
    return () => {
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }
      if (intervalRef.current) {
        clearInterval(intervalRef.current);
      }
    };
  }, [stream]);

  if (!show) {
    return null;
  }

  return (
    <div className={`fixed top-4 right-4 z-[9999] ${className}`}>
      <div className={`bg-black rounded-lg shadow-2xl border-2 border-gray-600 overflow-hidden transition-all duration-300 ${
        isMinimized ? 'w-20 h-16' : 'w-80 h-60'
      }`}>
        {/* Header con controles */}
        <div className="bg-gray-800 px-2 py-1 flex justify-between items-center">
          <span className="text-white text-xs font-medium">
            {isMinimized ? "üìπ" : "Webcam"}
          </span>
          <div className="flex gap-1">
            <button
              onClick={() => setIsMinimized(!isMinimized)}
              className="text-gray-400 hover:text-white text-xs p-1"
            >
              {isMinimized ? "‚ñ°" : "‚àí"}
            </button>
            <button
              onClick={closeWebcam}
              className="text-gray-400 hover:text-red-400 p-1"
            >
              <X className="w-3 h-3" />
            </button>
          </div>
        </div>

        {/* Video container */}
        {!isMinimized && (
          <div className="relative">
            <video
              ref={videoRef}
              autoPlay
              playsInline
              muted
              className="w-full h-56 object-cover"
              onPlay={handleVideoPlay}
            />
            <canvas ref={canvasRef} className="absolute top-0 left-0 w-full h-full" />
            
            {error && (
              <div className="absolute inset-0 bg-red-900/80 flex items-center justify-center p-2">
                <p className="text-white text-xs text-center">{error}</p>
              </div>
            )}

            {/* Control overlay */}
            <div className="absolute bottom-2 left-2 right-2 flex justify-center gap-2">
              <Button
                onClick={() => setFaceTrackingEnabled(!faceTrackingEnabled)}
                className={`${faceTrackingEnabled ? 'bg-green-600 hover:bg-green-700' : 'bg-gray-600 hover:bg-gray-700'} text-white rounded-full p-2`}
                size="sm"
                title={faceTrackingEnabled ? "Desactivar seguimiento facial" : "Activar seguimiento facial"}
              >
                {faceTrackingEnabled ? <Eye className="w-4 h-4" /> : <EyeOff className="w-4 h-4" />}
              </Button>
              <Button
                onClick={toggleWebcam}
                className="bg-red-600 hover:bg-red-700 text-white rounded-full p-2"
                size="sm"
              >
                <CameraOff className="w-4 h-4" />
              </Button>
            </div>
          </div>
        )}
      </div>
    </div>
  );
}